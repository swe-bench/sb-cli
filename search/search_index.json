{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Overview","text":"<p>SWE-bench CLI is a command-line tool for interacting with the SWE-bench API. This tool allows you to:</p> <ul> <li>Submit model predictions for evaluation</li> <li>Retrieve evaluation reports</li> <li>Manage your evaluation runs</li> <li>Track your model's performance</li> </ul> <p>All on the cloud!</p>"},{"location":"#key-features","title":"Key Features","text":"<ul> <li>Easy Submission: Submit your model's predictions with a single command</li> <li>Real-time Tracking: Monitor evaluation progress in real-time</li> <li>Run Management: Access and delete runs as needed</li> </ul>"},{"location":"#quick-links","title":"Quick Links","text":"<ul> <li>Installation: Get started with installing the CLI</li> <li>Authentication: Set up your API key</li> <li>Quick Start: Submit your first predictions</li> <li>User Guide: Detailed guide on using the CLI</li> </ul>"},{"location":"authentication/","title":"Authentication","text":"<p>Before using the SWE-bench CLI, you'll need to set up authentication using an API key.</p>"},{"location":"authentication/#getting-an-api-key","title":"Getting an API Key","text":"<ol> <li>Generate a new API key using your email:</li> </ol> <pre><code>sb-cli gen-api-key your.email@example.com\n</code></pre> <ol> <li>The CLI will output your API key. Save this key somewhere safe - you'll need it for all future operations.</li> </ol>"},{"location":"authentication/#setting-up-your-api-key","title":"Setting Up Your API Key","text":"<p>There are two ways to use your API key:</p>"},{"location":"authentication/#1-environment-setup-recommended","title":"1. Environment Setup (Recommended)","text":"<p>Set your API key as an environment variable:</p> <pre><code>export SWEBENCH_API_KEY=your_api_key\n</code></pre> <p>For permanent setup, add this line to your shell's configuration file (<code>.bashrc</code>, <code>.zshrc</code>, etc.).</p> <p>Note</p> <p>You can test that your key is working with <code>sb-cli get-quotas</code></p>"},{"location":"authentication/#2-command-line-option","title":"2. Command Line Option","text":"<p>Alternatively, you can pass your API key directly with each command:</p> <pre><code>sb-cli submit --api_key your_api_key ...\n</code></pre>"},{"location":"authentication/#verifying-your-api-key","title":"Verifying Your API Key","text":"<p>After receiving your API key, you'll get an email with a verification code. Verify your API key using:</p> <pre><code>sb-cli verify-api-key YOUR_VERIFICATION_CODE\n</code></pre>"},{"location":"installation/","title":"Installation","text":"<p>Installing the SWE-bench CLI is straightforward using pip.</p>"},{"location":"installation/#using-pip","title":"Using pip","text":"<pre><code>pip install sb-cli\n</code></pre>"},{"location":"installation/#verifying-installation","title":"Verifying Installation","text":"<p>After installation, verify that the CLI is working correctly:</p> <pre><code>sb-cli --help\n</code></pre> <p>You should see output listing all available commands.</p>"},{"location":"installation/#development-installation","title":"Development Installation","text":"<p>If you want to contribute or install from source:</p> <pre><code>git clone https://github.com/swe-bench/sb-cli.git\ncd sb-cli\npip install -e .\n</code></pre>"},{"location":"installation/#upgrading","title":"Upgrading","text":"<p>To upgrade to the latest version:</p> <pre><code>pip install --upgrade sb-cli\n</code></pre>"},{"location":"quick-start/","title":"Quick Start","text":"<p>This guide will help you submit your first predictions to SWE-bench and get an evaluation report.</p>"},{"location":"quick-start/#prerequisites","title":"Prerequisites","text":"<p>Before starting, ensure you have: - Installed the CLI (<code>pip install sb-cli</code>) - Generated and verified your API key (see Authentication) - Set up your <code>SWEBENCH_API_KEY</code> environment variable</p>"},{"location":"quick-start/#1-prepare-your-predictions","title":"1. Prepare Your Predictions","text":"<p>Create a JSON file (<code>preds.json</code>) with your model's predictions for the SWE-bench M <code>dev</code> split:</p> <pre><code>{\n    \"instance_id_1\": {\n        \"model_patch\": \"your code changes here\",\n        \"model_name_or_path\": \"your-model-name\"\n    },\n    \"instance_id_2\": {\n        \"model_patch\": \"more code changes\",\n        \"model_name_or_path\": \"your-model-name\"\n    }\n}\n</code></pre>"},{"location":"quick-start/#2-submit-predictions","title":"2. Submit Predictions","text":"<p>Submit your predictions to SWE-bench:</p> <pre><code>sb-cli submit swe-bench-m dev \\\n    --predictions_path preds.json \\\n    --run_id my_first_run\n</code></pre> <p>The CLI will: 1. Upload your predictions 2. Monitor the evaluation progress 3. Generate a report when complete</p>"},{"location":"quick-start/#3-check-results","title":"3. Check Results","text":"<p>You can access your evaluation report again by running:</p> <pre><code>sb-cli get-report swe-bench-m dev my_first_run\n</code></pre>"},{"location":"quick-start/#4-view-all-runs","title":"4. View All Runs","text":"<p>You can view all your submitted runs for <code>swe-bench-m</code> / <code>dev</code> by running:</p> <pre><code>sb-cli list-runs swe-bench-m dev\n</code></pre>"},{"location":"user-guide/","title":"User Guide Overview","text":"<p>This guide provides detailed information about using the SWE-bench CLI. Each command is documented with examples and common use cases.</p>"},{"location":"user-guide/#available-commands","title":"Available Commands","text":"<ul> <li>submit: Submit model predictions for evaluation</li> <li>get-report: Retrieve evaluation reports</li> <li>list-runs: View all your submitted runs</li> <li>delete-run: Remove a specific run</li> </ul>"},{"location":"user-guide/#dataset-information","title":"Dataset Information","text":"<p>SWE-bench has different subsets and splits available:</p>"},{"location":"user-guide/#subsets","title":"Subsets","text":"<ul> <li><code>swe-bench-m</code>: The main dataset</li> <li><code>swe-bench_lite</code>: A smaller subset for testing and development</li> </ul>"},{"location":"user-guide/#splits","title":"Splits","text":"<ul> <li><code>dev</code>: Development/validation split</li> <li><code>test</code>: Test split (currently only available for <code>swe-bench_lite</code>)</li> </ul>"},{"location":"user-guide/#common-workflows","title":"Common Workflows","text":"<ol> <li> <p>Basic Evaluation:    <pre><code>sb-cli submit swe-bench-m dev --predictions_path preds.json --run_id my_run\nsb-cli get-report swe-bench-m dev my_run\n</code></pre></p> </li> <li> <p>Development Testing:    <pre><code>sb-cli submit swe-bench_lite dev --predictions_path test.json --run_id test_run\n</code></pre></p> </li> <li> <p>Managing Runs:    <pre><code>sb-cli list-runs swe-bench-m dev\nsb-cli delete-run swe-bench-m dev old_run_id\n</code></pre></p> </li> </ol>"},{"location":"user-guide/delete-run/","title":"Delete Run Command","text":"<p>Warning</p> <p>This command is currently disabled.</p> <p>The <code>delete-run</code> command removes a specific run id and its associated data.</p>"},{"location":"user-guide/delete-run/#usage","title":"Usage","text":"<pre><code>sb-cli delete-run &lt;subset&gt; &lt;split&gt; &lt;run_id&gt;\n</code></pre>"},{"location":"user-guide/delete-run/#arguments","title":"Arguments","text":"<ul> <li><code>subset</code>: Dataset subset (<code>swe-bench-m</code> or <code>swe-bench_lite</code>)</li> <li><code>split</code>: Dataset split (<code>dev</code> or <code>test</code>)</li> <li><code>run_id</code>: ID of the run to delete</li> </ul>"},{"location":"user-guide/delete-run/#important-notes","title":"Important Notes","text":"<ul> <li>Deletion is permanent and cannot be undone</li> <li>Only runs associated with your API key can be deleted</li> <li>Running evaluations will be cancelled</li> <li>Associated reports will be removed</li> </ul>"},{"location":"user-guide/delete-run/#examples","title":"Examples","text":"<ol> <li>Delete a specific run: <pre><code>sb-cli delete-run swe-bench-m dev my_run_id\n</code></pre></li> </ol>"},{"location":"user-guide/delete-run/#best-practices","title":"Best Practices","text":"<ol> <li> <p>Always verify the run ID before deletion: <pre><code>sb-cli list-runs swe-bench-m dev\n</code></pre></p> </li> <li> <p>Save important reports before deletion: <pre><code>sb-cli get-report swe-bench-m dev my_run_id -o ./backup\nsb-cli delete-run swe-bench-m dev my_run_id\n</code></pre></p> </li> <li> <p>Consider keeping a local backup of important results before deletion</p> </li> </ol>"},{"location":"user-guide/get-quotas/","title":"Get Quotas Command","text":"<p>The <code>get-quotas</code> command displays your remaining submission quotas for each dataset subset and split combination.</p>"},{"location":"user-guide/get-quotas/#usage","title":"Usage","text":"<pre><code>sb-cli get-quotas\n</code></pre> <p>Example output: <pre><code>&gt; sb-cli get-quotas\n        Remaining Submission Quotas\n\u250f\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2533\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2513\n\u2503 Subset         \u2503 Split \u2503 Remaining Runs \u2503\n\u2521\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2547\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2529\n\u2502 swe-bench-m    \u2502 test  \u2502              1 \u2502\n\u2502 swe-bench-m    \u2502 dev   \u2502            997 \u2502\n\u2502 swe-bench_lite \u2502 test  \u2502              1 \u2502\n\u2502 swe-bench_lite \u2502 dev   \u2502            976 \u2502\n\u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2534\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\n</code></pre></p>"},{"location":"user-guide/get-quotas/#options","title":"Options","text":"<ul> <li><code>--api_key</code>: API key to use (defaults to <code>SWEBENCH_API_KEY</code> environment variable)</li> </ul>"},{"location":"user-guide/get-quotas/#output-format","title":"Output Format","text":"<p>The command displays a table with three columns: - Subset: Dataset subset (<code>swe-bench-m</code> or <code>swe-bench_lite</code>) - Split: Dataset split (<code>dev</code> or <code>test</code>) - Remaining Runs: Number of submissions remaining for this subset/split combination</p> <p>This command will display the remaining submissions you can make for each dataset subset and split combination.</p>"},{"location":"user-guide/get-quotas/#notes","title":"Notes","text":"<ul> <li>Quotas are refreshed periodically according to your subscription level</li> </ul>"},{"location":"user-guide/get-report/","title":"Get Report Command","text":"<p>The <code>get-report</code> command retrieves evaluation results for a specific run.</p>"},{"location":"user-guide/get-report/#usage","title":"Usage","text":"<pre><code>sb-cli get-report &lt;subset&gt; &lt;split&gt; &lt;run_id&gt; [options]\n</code></pre>"},{"location":"user-guide/get-report/#arguments","title":"Arguments","text":"<ul> <li><code>subset</code>: Dataset subset (<code>swe-bench-m</code> or <code>swe-bench_lite</code>)</li> <li><code>split</code>: Dataset split (<code>dev</code> or <code>test</code>)</li> <li><code>run_id</code>: ID of the run to get results for</li> </ul>"},{"location":"user-guide/get-report/#options","title":"Options","text":"<ul> <li><code>--output_dir</code>, <code>-o</code>: Directory to save report files (default: sb-cli-reports)</li> <li><code>--overwrite</code>: Overwrite existing report files (0/1, default: 0)</li> <li><code>--extra_arg</code>, <code>-e</code>: Additional arguments in KEY=VALUE format</li> </ul>"},{"location":"user-guide/get-report/#report-format","title":"Report Format","text":"<p>The command outputs a summary to the console and saves two JSON files:</p> <ol> <li><code>{subset}__{split}__{run_id}.json</code>: The full evaluation report</li> <li><code>{subset}__{split}__{run_id}.response.json</code>: Additional response data</li> </ol> <p>The console summary includes: - Resolved instances (total and submitted) - Submission statistics - Error counts - Pending evaluations</p>"},{"location":"user-guide/get-report/#examples","title":"Examples","text":"<ol> <li> <p>Basic usage: <pre><code>sb-cli get-report swe-bench-m dev my_run_id\n</code></pre></p> </li> <li> <p>Custom output directory: <pre><code>sb-cli get-report swe-bench-m dev my_run_id -o ./reports\n</code></pre></p> </li> <li> <p>Overwrite existing report: <pre><code>sb-cli get-report swe-bench-m dev my_run_id --overwrite 1\n</code></pre></p> </li> </ol>"},{"location":"user-guide/list-runs/","title":"List Runs Command","text":"<p>The <code>list-runs</code> command shows all your submitted runs for a specific subset and split.</p>"},{"location":"user-guide/list-runs/#usage","title":"Usage","text":"<pre><code>sb-cli list-runs &lt;subset&gt; &lt;split&gt;\n</code></pre>"},{"location":"user-guide/list-runs/#arguments","title":"Arguments","text":"<ul> <li><code>subset</code>: Dataset subset (<code>swe-bench-m</code> or <code>swe-bench_lite</code>)</li> <li><code>split</code>: Dataset split (<code>dev</code> or <code>test</code>)</li> </ul>"},{"location":"user-guide/list-runs/#output","title":"Output","text":"<p>The command displays a list of all run IDs associated with your API key for the specified subset and split. If no runs are found, it will indicate this.</p>"},{"location":"user-guide/list-runs/#examples","title":"Examples","text":"<ol> <li> <p>List runs for main dataset: <pre><code>sb-cli list-runs swe-bench-m dev\n</code></pre></p> </li> <li> <p>List runs for lite dataset: <pre><code>sb-cli list-runs swe-bench_lite dev\n</code></pre></p> </li> </ol>"},{"location":"user-guide/list-runs/#common-use-cases","title":"Common Use Cases","text":"<ul> <li>Finding old run IDs before deletion</li> <li>Checking submission history</li> <li>Verifying successful submissions</li> <li>Managing multiple experiments</li> </ul>"},{"location":"user-guide/submit/","title":"Submit Command","text":"<p>The <code>submit</code> command uploads your model's predictions for evaluation.</p>"},{"location":"user-guide/submit/#usage","title":"Usage","text":"<pre><code>sb-cli submit &lt;subset&gt; &lt;split&gt; --predictions_path &lt;path&gt; [options]\n</code></pre>"},{"location":"user-guide/submit/#arguments","title":"Arguments","text":"<ul> <li><code>subset</code>: Dataset subset (<code>swe-bench-m</code> or <code>swe-bench_lite</code>)</li> <li><code>split</code>: Dataset split (<code>dev</code> or <code>test</code>)</li> </ul>"},{"location":"user-guide/submit/#options","title":"Options","text":"<ul> <li><code>--predictions_path</code>: Path to your predictions file (required)</li> <li><code>--run_id</code>: Unique identifier for this submission. You can use the values PARENT or STEM to use the parent directory name or the stem of the predictions file name. (default: PARENT)</li> <li><code>--instance_ids</code>: Comma-separated list of specific instances to submit</li> <li><code>--output_dir</code>: Directory to save report files (default: sb-cli-reports)</li> <li><code>--overwrite</code>: Overwrite existing report (0/1, default: 0)</li> <li><code>--gen_report</code>: Generate report after completion (0/1, default: 1)</li> <li><code>--verify_submission</code>: Verify submission before waiting (0/1, default: 1)</li> <li><code>--wait_for_evaluation</code>: Wait for evaluation to complete (0/1, default: 1)</li> </ul>"},{"location":"user-guide/submit/#predictions-file-format","title":"Predictions File Format","text":"<p>Your predictions file should be a JSON file in one of these formats:</p>"},{"location":"user-guide/submit/#dictionary-format","title":"Dictionary Format","text":"<pre><code>{\n    \"instance_id_1\": {\n        \"model_patch\": \"...\",\n        \"model_name_or_path\": \"...\"\n    },\n    \"instance_id_2\": {\n        \"model_patch\": \"...\",\n        \"model_name_or_path\": \"...\"\n    }\n}\n</code></pre>"},{"location":"user-guide/submit/#list-format","title":"List Format","text":"<pre><code>[\n    {\n        \"instance_id\": \"instance_id_1\",\n        \"model_patch\": \"...\",\n        \"model_name_or_path\": \"...\"\n    },\n    {\n        \"instance_id\": \"instance_id_2\",\n        \"model_patch\": \"...\",\n        \"model_name_or_path\": \"...\"\n    }\n]\n</code></pre>"},{"location":"user-guide/submit/#examples","title":"Examples","text":"<ol> <li> <p>Basic submission: <pre><code>sb-cli submit swe-bench-m dev --predictions_path preds.json\n</code></pre></p> </li> <li> <p>Custom run ID and output directory: <pre><code>sb-cli submit swe-bench-m dev \\\n    --predictions_path preds.json \\\n    --run_id custom_run \\\n    --output_dir ./reports\n</code></pre></p> </li> <li> <p>Submit specific instances: <pre><code>sb-cli submit swe-bench-m dev \\\n    --predictions_path preds.json \\\n    --instance_ids id1,id2,id3\n</code></pre></p> </li> </ol>"}]}